{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65c6cd9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b051150",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent / 'preprocess/data'\n",
    "temp_path = Path.cwd() / 'data'\n",
    "if not temp_path.is_dir():\n",
    "    temp_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a890ee3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db50c44",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "lb_in = data_path / 'lb'\n",
    "lb_out = temp_path / 'lb'\n",
    "if not lb_out.is_dir():\n",
    "    lb_out.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9e36e9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [02:17<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "train_path = lb_in / 'train_parquet'\n",
    "\n",
    "sentences = []\n",
    "for train_file in tqdm(sorted(train_path.glob('*.parquet'))):\n",
    "    data = cudf.read_parquet(train_file.as_posix(), columns=['session', 'aid', 'ts'])\n",
    "\n",
    "    data = data.sort_values('ts', ascending=True, ignore_index=True)\n",
    "    data = data.drop('ts', axis=1)\n",
    "\n",
    "    data = data.groupby(['session']).agg(list)\n",
    "\n",
    "    sentences.extend(data['aid'].to_arrow().to_pylist())\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2564c054",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12899779\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3280888",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 6min 53s, sys: 1min 15s, total: 3h 8min 8s\n",
      "Wall time: 19min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w2vec = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    vector_size=50, \n",
    "    epochs=5, \n",
    "    sg=1, \n",
    "    window=3, \n",
    "    sample=1e-3, \n",
    "    ns_exponent=1, \n",
    "    min_count=1, \n",
    "    workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb64e73",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "w2vec_vectors = w2vec.wv\n",
    "w2vec_vectors.save((lb_out / 'w2vec.wordvectors').as_posix())\n",
    "\n",
    "del w2vec, w2vec_vectors, sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617026e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c3862e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "cv_in = data_path / 'cv'\n",
    "cv_out = temp_path / 'cv'\n",
    "if not cv_out.is_dir():\n",
    "    cv_out.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be362582",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [01:39<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path = cv_in / 'train_parquet'\n",
    "\n",
    "sentences = []\n",
    "for train_file in tqdm(sorted(train_path.glob('*.parquet'))):\n",
    "    data = cudf.read_parquet(train_file.as_posix(), columns=['session', 'aid', 'ts'])\n",
    "\n",
    "    data = data.sort_values('ts', ascending=True, ignore_index=True)\n",
    "    data = data.drop('ts', axis=1)\n",
    "\n",
    "    data = data.groupby(['session']).agg(list)\n",
    "\n",
    "    sentences.extend(data['aid'].to_arrow().to_pylist())\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7efc49ed",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10584517\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "042ccc5e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 21min 32s, sys: 52.5 s, total: 2h 22min 24s\n",
      "Wall time: 16min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w2vec = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    vector_size=50, \n",
    "    epochs=5, \n",
    "    sg=1, \n",
    "    window=3, \n",
    "    sample=1e-3, \n",
    "    ns_exponent=1, \n",
    "    min_count=1, \n",
    "    workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8df928f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec_vectors = w2vec.wv\n",
    "w2vec_vectors.save((cv_out / 'w2vec.wordvectors').as_posix())\n",
    "\n",
    "del w2vec, w2vec_vectors, sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (otto-recsys)",
   "language": "python",
   "name": "otto-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
